{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados das eleições dos anos de 2006 e 2010\n",
    "data = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "#removendo variáveis irrelevantes\n",
    "data = data.drop(columns=['sequencial_candidato', 'nome'])\n",
    "\n",
    "#selecionando atributos numéricos\n",
    "numeric_feats = data.dtypes[data.dtypes != \"object\"].index\n",
    "\n",
    "#normalizando variáveis numéricas exceto ano\n",
    "data[numeric_feats[1:]] = np.log1p(data[numeric_feats[1:]])\n",
    "\n",
    "#dummy das variáveis categoricas\n",
    "X_train = data.drop(columns=['situacao'])\n",
    "X_train = pd.get_dummies(X_train)\n",
    "#dumy da variável alvo, eleito = 1 e nao_eleito = 0\n",
    "Y_train = data.situacao\n",
    "Y_train = Y_train.replace(['nao_eleito', 'eleito'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotando distribuição da variável alvo\n",
    "sns.countplot(Y_train)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes estão claramente desbalanceadas, essa diferença pode enviesar a aprendizagem do modelo.Isso pode ser tratrado por meio de técnicas de `Under-sampling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para calcular o AUC-Precision&Recall na validação cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def f1_cv(model, X, Y):\n",
    "    f1 = cross_val_score(model, X, Y, scoring='f1', cv=5)\n",
    "    return(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logistíca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lambdas = np.arange(0.01,2,0.01).tolist()\n",
    "\n",
    "cv_logRegression = [f1_cv(LogisticRegression(solver=\"lbfgs\", max_iter=10000, C=lbd, random_state=1)).mean()\n",
    "                    for lbd in lambdas]\n",
    "cv_logRegression = pd.Series(cv_logRegression, index = lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cv_logRegression.plot(title = \"Cross validation - Logistic Regression\")\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.show()\n",
    "print(\"O melhor alpha é {0}, com F1 = {1}\".format(cv_logRegression.idxmax(), cv_logRegression.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neighbors = np.arange(1,100,1).tolist()\n",
    "cv_knn = [f1_cv(KNeighborsClassifier(n_neighbors=neighbor)).mean() \n",
    "            for neighbor in neighbors]\n",
    "cv_knn = pd.Series(cv_knn, index = neighbors)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_knn.plot(title = \"Cross validation - KNN\")\n",
    "plt.xlabel(\"Neighbor\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A melhor quantidade de vizinhos é {0}, com F1 = {1}\".format(cv_knn.idxmax(), cv_knn.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "depths = np.arange(1,15,1).tolist()\n",
    "cv_tree = [f1_cv(tree.DecisionTreeClassifier(max_depth = depth)).mean() \n",
    "            for depth in depths]\n",
    "cv_tree = pd.Series(cv_tree, index = depths)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_tree.plot(title = \"Cross validation - Decision Tree\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A profundidade ideal é {0}, com F1 = {1}\".format(cv_tree.idxmax(), cv_tree.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso é claro o viés causado pelo desbalanceamento das classes, a melhor profundidade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "estimators = np.arange(1,50,1).tolist()\n",
    "cv_ada =  [f1_cv(AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), \n",
    "                                    algorithm=\"SAMME\", \n",
    "                                    n_estimators=estimator)).mean() \n",
    "            for estimator in estimators]\n",
    "cv_ada = pd.Series(cv_ada, index = estimators)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_ada.plot(title = \"Cross validation - Adaboost\")\n",
    "plt.xlabel(\"Estimator\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A quantidade de árvores ideal é {0}, com F1 = {1}\".format(cv_ada.idxmax(), cv_ada.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competição Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver o problema do desbalanceamento entre as classe vou utilizar a técnica de under-sampling NearMiss version 1, que pioriza a fronteira de decisão entre as classes. Deste modo é esperado que os modelos tenham um desempenho melhor, já que não sofrem mais com o viés da classe majoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanceando as classes\n",
    "from imblearn.under_sampling import NearMiss\n",
    "nm = NearMiss(version=3)\n",
    "X_train_balanced, Y_train_balanced = nm.fit_resample(X_train, Y_train)\n",
    "#plotando distribuição da variável alvo\n",
    "sns.countplot(Y_train_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lambdas = np.arange(0.01,2,0.01).tolist()\n",
    "cv_logRegression = [f1_cv(LogisticRegression(solver=\"lbfgs\", max_iter=10000, C=lbd, random_state=1), \n",
    "                          X_train_balanced, Y_train_balanced).mean()\n",
    "                    for lbd in lambdas]\n",
    "cv_logRegression = pd.Series(cv_logRegression, index = lambdas)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_logRegression.plot(title = \"Cross validation - Logistic Regression\")\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.show()\n",
    "print(\"O melhor alpha é {0}, com F1 = {1}\".format(cv_logRegression.idxmax(), cv_logRegression.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LogisticRegression(solver=\"lbfgs\", max_iter=10000, C=0.03, random_state=1)\n",
    "m.fit(X_train_balanced, Y_train_balanced)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Y_train, m.predict(X_train), output_dict=True)[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neighbors = np.arange(1,50,1).tolist()\n",
    "cv_knn = [f1_cv(KNeighborsClassifier(n_neighbors=neighbor)).mean() \n",
    "            for neighbor in neighbors]\n",
    "cv_knn = pd.Series(cv_knn, index = neighbors)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_knn.plot(title = \"Cross validation - KNN\")\n",
    "plt.xlabel(\"Neighbor\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A melhor quantidade de vizinhos é {0}, com F1 = {1}\".format(cv_knn.idxmax(), cv_knn.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "depths = np.arange(1,15,1).tolist()\n",
    "cv_tree = [f1_cv(tree.DecisionTreeClassifier(max_depth = depth)).mean() \n",
    "            for depth in depths]\n",
    "cv_tree = pd.Series(cv_tree, index = depths)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_tree.plot(title = \"Cross validation - Decision Tree\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A profundidade ideal é {0}, com F1 = {1}\".format(cv_tree.idxmax(), cv_tree.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "estimators = np.arange(1,50,1).tolist()\n",
    "cv_ada =  [f1_cv(AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), \n",
    "                                    algorithm=\"SAMME\", \n",
    "                                    n_estimators=estimator)).mean() \n",
    "            for estimator in estimators]\n",
    "cv_ada = pd.Series(cv_ada, index = estimators)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_ada.plot(title = \"Cross validation - Adaboost\")\n",
    "plt.xlabel(\"Estimator\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A quantidade de árvores ideal é {0}, com F1 = {1}\".format(cv_ada.idxmax(), cv_ada.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "trees = np.arange(1,15,1).tolist()\n",
    "cv_random_forest = [f1_cv(RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)).mean() \n",
    "                    for trees in trees]\n",
    "cv_random_forest = pd.Series(cv_random_forest, index = trees)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_random_forest.plot(title = \"Cross validation - Random Forest\")\n",
    "plt.xlabel(\"Tree\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A quantidade de árvores ideal é {0}, com F1 = {1}\".format(cv_random_forest.idxmax(), cv_random_forest.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "estimators = np.arange(1,50,1).tolist()\n",
    "cv_gb =  [f1_cv(GradientBoostingClassifier(n_estimators=estimator, learning_rate=1.0,\n",
    "                 max_depth=1, random_state=0)).mean() \n",
    "            for estimator in estimators]\n",
    "cv_gb = pd.Series(cv_gb, index = estimators)\n",
    "\n",
    "#plot do AUC-Precision&Recall na validação cruzada\n",
    "cv_gb.plot(title = \"Cross validation - Adaboost\")\n",
    "plt.xlabel(\"Estimator\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "print(\"A quantidade de árvores ideal é {0}, com F1 = {1}\".format(cv_gb.idxmax(), cv_gb.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogo/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "#variavel alvo\n",
    "Y_train = data.situacao\n",
    "data.drop(columns=['situacao'])\n",
    "\n",
    "data = pd.concat((data,test))\n",
    "\n",
    "#removendo variáveis irrelevantes\n",
    "data = data.drop(columns=['sequencial_candidato', 'nome'])\n",
    "\n",
    "#selecionando atributos numéricos\n",
    "numeric_feats = data.dtypes[data.dtypes != \"object\"].index\n",
    "\n",
    "#normalizando variáveis numéricas exceto ano\n",
    "data[numeric_feats[1:]] = np.log1p(data[numeric_feats[1:]])\n",
    "\n",
    "#dummy das variáveis categoricas\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "X_train = data.loc[data['ano'] != 2014]\n",
    "test = data.loc[data['ano'] == 2014]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression(solver=\"lbfgs\", max_iter=10000, C=0.03, random_state=1)\n",
    "m.fit(X_train, Y_train)\n",
    "predict = m.predict(test)\n",
    "predict = pd.DataFrame(predict)\n",
    "predict.to_csv(\"submission_sample\", sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
